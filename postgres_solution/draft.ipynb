{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2738ee3",
   "metadata": {},
   "source": [
    "# Contract Analysis with Azure Content Understanding\n",
    "\n",
    "This notebook demonstrates how to extract and analyze information from contract documents using Microsoft's Azure Content Understanding service (part of Azure AI Foundry).\n",
    "\n",
    "## Prerequisites\n",
    "- Azure subscription with Microsoft Foundry resource\n",
    "- Content Understanding endpoint with autodeployment enabled for required models\n",
    "- RBAC role: Cognitive Services User assigned to your user/managed identity\n",
    "- PDF contract files in the `contracts/` folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ae2615",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac0c392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for Azure Content Understanding\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974d75cc",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da70d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "\n",
    "print(\"‚úì Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba5e545",
   "metadata": {},
   "source": [
    "## Step 3: Configure Azure Authentication (RBAC)\n",
    "\n",
    "Using Azure RBAC with `DefaultAzureCredential` for secure authentication.\n",
    "\n",
    "**To set up:**\n",
    "1. Go to [Azure Portal](https://portal.azure.com)\n",
    "2. Create a **\"Microsoft Foundry\"** resource in a supported region\n",
    "3. Enable autodeployment for required models (GPT-4.1, GPT-4.1-mini, text-embedding-3-large)\n",
    "4. Assign yourself the **\"Cognitive Services User\"** role:\n",
    "   - Go to your Foundry resource ‚Üí Access Control (IAM)\n",
    "   - Click \"Add role assignment\"\n",
    "   - Select \"Cognitive Services User\" role\n",
    "   - Assign to yourself or your managed identity\n",
    "5. Set environment variable for endpoint or configure in code\n",
    "6. Authenticate using: `az login` (Azure CLI) or use managed identity in Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e4387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Content Understanding endpoint\n",
    "\n",
    "# Base endpoint for your Cognitive Services resource\n",
    "\n",
    "base_endpoint = \"https://___-contracts-ai-proj-resource.cognitiveservices.azure.com\"\n",
    "api_version = \"2025-11-01\"\n",
    "analyzer_id = \"prebuilt-contract\"  # Use prebuilt contract analyzer\n",
    "analyzer_id = \"projectAnalyzer_1768587228991_591\"\n",
    "endpoint = f\"{base_endpoint}/contentunderstanding/analyzers/{analyzer_id}:analyzeBinary?api-version={api_version}\"\n",
    "\n",
    "# Use DefaultAzureCredential for RBAC authentication\n",
    "credential = DefaultAzureCredential()\n",
    "token = credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {token.token}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648f842c",
   "metadata": {},
   "source": [
    "## Step 4: Load Contract Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82b62f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all PDF files from the contracts folder\n",
    "contracts_dir = Path(\"contracts\")\n",
    "contract_files = list(contracts_dir.glob(\"*.pdf\"))\n",
    "\n",
    "print(f\"Found {len(contract_files)} contract files:\")\n",
    "for file in contract_files:\n",
    "    print(f\"  - {file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5823308b",
   "metadata": {},
   "source": [
    "## Step 5: Extract Information Using Azure Content Understanding\n",
    "\n",
    "Azure Content Understanding prebuilt analyzers can extract:\n",
    "- **Parties** involved and their roles\n",
    "- **Contract dates** (effective, expiration, execution)\n",
    "- **Contract value/amount** and payment terms\n",
    "- **Clauses** with titles, types, and full content (using custom analyzer)\n",
    "- **Terms and conditions** in structured format\n",
    "- Document structure, tables, key-value pairs, and more\n",
    "\n",
    "We'll use custom analyzers with schema-based extraction for contracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c55d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import re\n",
    "\n",
    "def analyze_contract(file_path):\n",
    "    \"\"\"\n",
    "    Analyze a contract using Azure Content Understanding with analyzeBinary endpoint.\n",
    "    Returns structured data extracted from the contract.\n",
    "    \"\"\"\n",
    "    print(f\"\\nAnalyzing: {file_path.name}\")\n",
    "\n",
    "    # Read the raw binary file content\n",
    "    with open(file_path, 'rb') as f:\n",
    "        file_content = f.read()\n",
    "\n",
    "    print(f\"  File size: {len(file_content)} bytes\")\n",
    "\n",
    "    # Headers for binary upload - set Content-Type to the actual file type\n",
    "    binary_headers = {\n",
    "        \"Authorization\": f\"Bearer {token.token}\",\n",
    "        \"Content-Type\": \"application/pdf\"\n",
    "    }\n",
    "\n",
    "    # Step 1: Submit analysis request\n",
    "    print(\"  Submitting to Azure Content Understanding...\")\n",
    "    print(f\"  Endpoint: {endpoint}\")\n",
    "\n",
    "    # Use data= for raw binary, NOT json=\n",
    "    response = requests.post(endpoint, headers=binary_headers, data=file_content)\n",
    "\n",
    "    print(f\"  Response status: {response.status_code}\")\n",
    "\n",
    "    if response.status_code != 202:\n",
    "        print(f\"‚ùå Error: {response.status_code}\")\n",
    "        print(f\"  Response body: {response.text}\")\n",
    "        return {\n",
    "            \"filename\": file_path.name,\n",
    "            \"error\": f\"API returned status {response.status_code}: {response.text}\"\n",
    "        }\n",
    "\n",
    "    # Get the Operation-Location header for polling results\n",
    "    operation_location = response.headers.get('Operation-Location')\n",
    "    print(f\"  Operation-Location: {operation_location}\")\n",
    "\n",
    "    if not operation_location:\n",
    "        print(\"‚ùå No Operation-Location header in response\")\n",
    "        return {\n",
    "            \"filename\": file_path.name,\n",
    "            \"error\": \"No Operation-Location header\"\n",
    "        }\n",
    "\n",
    "    print(f\"  Results URL: {operation_location}\")\n",
    "\n",
    "    # Step 2: Poll for results (use JSON headers for GET requests)\n",
    "    print(\"  Waiting for analysis to complete...\")\n",
    "    poll_headers = {\n",
    "        \"Authorization\": f\"Bearer {token.token}\"\n",
    "    }\n",
    "\n",
    "    max_retries = 60\n",
    "    retry_count = 0\n",
    "\n",
    "    while retry_count < max_retries:\n",
    "        time.sleep(2)  # Wait 2 seconds between polls\n",
    "        result_response = requests.get(operation_location, headers=poll_headers)\n",
    "\n",
    "        if result_response.status_code == 200:\n",
    "            result_data = result_response.json()\n",
    "            status = result_data.get('status')\n",
    "            print(f\"  Status: {status}\")\n",
    "\n",
    "            if status == 'Succeeded':\n",
    "                # Extract structured data from result\n",
    "                result_contents = result_data.get('result', {}).get('contents', [])\n",
    "\n",
    "                if result_contents:\n",
    "                    content = result_contents[0]\n",
    "                    fields = content.get('fields', {})\n",
    "\n",
    "                    # Map fields to our structure using contract-specific extractors\n",
    "                    extracted_data = {\n",
    "                        \"filename\": file_path.name,\n",
    "                        \"title\": extract_contract_title(fields),\n",
    "                        \"parties\": extract_parties(fields),\n",
    "                        \"dates\": extract_dates(fields),\n",
    "                        \"duration\": extract_duration(fields),\n",
    "                        \"jurisdictions\": extract_jurisdictions(fields),\n",
    "                        \"clauses\": extract_clauses(fields),\n",
    "                        \"raw_fields\": fields,\n",
    "                        \"markdown\": content.get('markdown', '')\n",
    "                    }\n",
    "\n",
    "                    print(f\"‚úì Analysis complete\")\n",
    "                    return extracted_data\n",
    "                else:\n",
    "                    print(\"‚ö†Ô∏è No content in result\")\n",
    "                    return {\n",
    "                        \"filename\": file_path.name,\n",
    "                        \"raw_result\": result_data\n",
    "                    }\n",
    "\n",
    "            elif status in ['Failed', 'Canceled']:\n",
    "                print(f\"‚ùå Analysis {status.lower()}\")\n",
    "                error_info = result_data.get('error', {})\n",
    "                print(f\"  Error: {error_info}\")\n",
    "                return {\n",
    "                    \"filename\": file_path.name,\n",
    "                    \"error\": f\"Analysis {status.lower()}: {error_info}\"\n",
    "                }\n",
    "\n",
    "            # Status is Running or NotStarted, continue polling\n",
    "        else:\n",
    "            print(f\"  Poll response: {result_response.status_code}\")\n",
    "\n",
    "        retry_count += 1\n",
    "\n",
    "    print(\"‚ùå Timeout waiting for results\")\n",
    "    return {\n",
    "        \"filename\": file_path.name,\n",
    "        \"error\": \"Timeout\"\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_field_value(field_data):\n",
    "    \"\"\"\n",
    "    Helper function to extract values from Content Understanding field structure.\n",
    "    Handles string, date, number, array, and object types.\n",
    "    \"\"\"\n",
    "    if not field_data:\n",
    "        return None\n",
    "    \n",
    "    field_type = field_data.get('type')\n",
    "    \n",
    "    if field_type == 'array':\n",
    "        return [extract_field_value(item) for item in field_data.get('valueArray', [])]\n",
    "    elif field_type == 'object':\n",
    "        obj = {}\n",
    "        for key, value in field_data.get('valueObject', {}).items():\n",
    "            obj[key] = extract_field_value(value)\n",
    "        return obj\n",
    "    elif field_type == 'string':\n",
    "        return field_data.get('valueString')\n",
    "    elif field_type == 'number':\n",
    "        return field_data.get('valueNumber')\n",
    "    elif field_type == 'date':\n",
    "        return field_data.get('valueDate')\n",
    "    else:\n",
    "        return field_data.get('content', field_data.get('valueString'))\n",
    "\n",
    "\n",
    "def extract_contract_title(fields):\n",
    "    \"\"\"Extract contract title from fields.\"\"\"\n",
    "    return extract_field_value(fields.get('Title'))\n",
    "\n",
    "\n",
    "def extract_parties(fields):\n",
    "    \"\"\"\n",
    "    Extract party information from contract fields.\n",
    "    Structure: Parties.valueArray[].valueObject.{Name, Address, ReferenceName, Clause}\n",
    "    \"\"\"\n",
    "    parties = []\n",
    "    \n",
    "    parties_field = fields.get('Parties', {})\n",
    "    parties_array = parties_field.get('valueArray', [])\n",
    "    \n",
    "    for party_item in parties_array:\n",
    "        if party_item.get('type') == 'object':\n",
    "            party_obj = party_item.get('valueObject', {})\n",
    "            \n",
    "            party_data = {\n",
    "                \"name\": extract_field_value(party_obj.get('Name')),\n",
    "                \"address\": extract_field_value(party_obj.get('Address')),\n",
    "                \"reference_name\": extract_field_value(party_obj.get('ReferenceName')),\n",
    "                \"clause\": extract_field_value(party_obj.get('Clause'))\n",
    "            }\n",
    "            \n",
    "            # Only add if we have at least a name\n",
    "            if party_data[\"name\"]:\n",
    "                # Clean up None values\n",
    "                party_data = {k: v for k, v in party_data.items() if v is not None}\n",
    "                parties.append(party_data)\n",
    "    \n",
    "    return parties\n",
    "\n",
    "\n",
    "def extract_dates(fields):\n",
    "    \"\"\"\n",
    "    Extract date information from contract fields.\n",
    "    Available dates: ExecutionDate, EffectiveDate, ExpirationDate, RenewalDate\n",
    "    \"\"\"\n",
    "    dates = {}\n",
    "    \n",
    "    date_fields = ['ExecutionDate', 'EffectiveDate', 'ExpirationDate', 'RenewalDate']\n",
    "    \n",
    "    for date_field in date_fields:\n",
    "        date_value = extract_field_value(fields.get(date_field))\n",
    "        if date_value:\n",
    "            dates[date_field] = date_value\n",
    "    \n",
    "    return dates\n",
    "\n",
    "\n",
    "def extract_duration(fields):\n",
    "    \"\"\"Extract contract duration from fields.\"\"\"\n",
    "    return extract_field_value(fields.get('ContractDuration'))\n",
    "\n",
    "\n",
    "def extract_jurisdictions(fields):\n",
    "    \"\"\"\n",
    "    Extract jurisdiction information from contract fields.\n",
    "    Structure: Jurisdictions.valueArray[]\n",
    "    \"\"\"\n",
    "    jurisdictions_field = fields.get('Jurisdictions', {})\n",
    "    jurisdictions_array = jurisdictions_field.get('valueArray', [])\n",
    "    \n",
    "    jurisdictions = []\n",
    "    for item in jurisdictions_array:\n",
    "        value = extract_field_value(item)\n",
    "        if value:\n",
    "            jurisdictions.append(value)\n",
    "    \n",
    "    return jurisdictions\n",
    "\n",
    "\n",
    "def extract_clauses(fields):\n",
    "    \"\"\"\n",
    "    Extract clause information from contract fields.\n",
    "    Structure: Clauses.valueArray[].valueObject.{clauseType, clauseTitle, clauseText}\n",
    "    \"\"\"\n",
    "    clauses = []\n",
    "    \n",
    "    clauses_field = fields.get('Clauses', {})\n",
    "    clauses_array = clauses_field.get('valueArray', [])\n",
    "    \n",
    "    for clause_item in clauses_array:\n",
    "        if clause_item.get('type') == 'object':\n",
    "            clause_obj = clause_item.get('valueObject', {})\n",
    "            \n",
    "            clause_data = {\n",
    "                \"type\": extract_field_value(clause_obj.get('clauseType')),\n",
    "                \"title\": extract_field_value(clause_obj.get('clauseTitle')),\n",
    "                \"text\": extract_field_value(clause_obj.get('clauseText'))\n",
    "            }\n",
    "            \n",
    "            # Only add if we have at least a title or text\n",
    "            if clause_data[\"title\"] or clause_data[\"text\"]:\n",
    "                # Clean up None values\n",
    "                clause_data = {k: v for k, v in clause_data.items() if v is not None}\n",
    "                clauses.append(clause_data)\n",
    "    \n",
    "    return clauses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dd1a69",
   "metadata": {},
   "source": [
    "## Step 6: Process All Contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d31819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze all contracts\n",
    "all_contract_data = []\n",
    "\n",
    "for contract_file in contract_files:\n",
    "    try:\n",
    "        data = analyze_contract(contract_file)\n",
    "        all_contract_data.append(data)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {contract_file.name}: {str(e)}\")\n",
    "\n",
    "print(f\"\\n‚úì Successfully processed {len(all_contract_data)} contracts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b96ecb8",
   "metadata": {},
   "source": [
    "## Step 7: View Extracted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd0f940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display extracted data for each contract\n",
    "for contract in all_contract_data:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Contract: {contract['filename']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Title\n",
    "    if contract.get('title'):\n",
    "        print(f\"\\nüìÑ Title: {contract['title']}\")\n",
    "    \n",
    "    # Parties\n",
    "    print(\"\\nüìã Parties:\")\n",
    "    parties = contract.get('parties', [])\n",
    "    if parties:\n",
    "        for party in parties:\n",
    "            print(f\"  ‚Ä¢ {party.get('name', 'Unknown')}\")\n",
    "            if party.get('address'):\n",
    "                print(f\"    Address: {party['address']}\")\n",
    "            if party.get('reference_name'):\n",
    "                print(f\"    Reference: {party['reference_name']}\")\n",
    "    else:\n",
    "        print(\"  No parties extracted\")\n",
    "    \n",
    "    # Dates\n",
    "    print(\"\\nüìÖ Dates:\")\n",
    "    dates = contract.get('dates', {})\n",
    "    if dates:\n",
    "        for date_type, date_value in dates.items():\n",
    "            print(f\"  {date_type}: {date_value}\")\n",
    "    else:\n",
    "        print(\"  No dates extracted\")\n",
    "    \n",
    "    # Duration\n",
    "    duration = contract.get('duration')\n",
    "    if duration:\n",
    "        print(f\"\\n‚è±Ô∏è Duration: {duration}\")\n",
    "    \n",
    "    # Jurisdictions\n",
    "    jurisdictions = contract.get('jurisdictions', [])\n",
    "    if jurisdictions:\n",
    "        print(f\"\\nüåç Jurisdictions: {', '.join(jurisdictions)}\")\n",
    "    \n",
    "    # Clauses\n",
    "    print(f\"\\nüìù Clauses ({len(contract.get('clauses', []))} found):\")\n",
    "    clauses = contract.get('clauses', [])\n",
    "    if clauses:\n",
    "        for i, clause in enumerate(clauses, 1):\n",
    "            print(f\"\\n  [{i}] {clause.get('title', 'Untitled')}\")\n",
    "            if clause.get('type'):\n",
    "                print(f\"      Type: {clause['type']}\")\n",
    "            if clause.get('text'):\n",
    "                text_preview = clause['text'][:150] + \"...\" if len(clause['text']) > 150 else clause['text']\n",
    "                print(f\"      Text: {text_preview}\")\n",
    "    else:\n",
    "        print(\"  No clauses extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d33ecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "import psycopg2\n",
    "\n",
    "# Create tables for contracts, clauses, and parties\n",
    "\n",
    "# Connection parameters\n",
    "server_name = \"contract-db\"\n",
    "database_name = \"postgres\"\n",
    "host = f\"{server_name}.postgres.database.azure.com\"\n",
    "port = 5432\n",
    "\n",
    "# Get access token using Azure AD authentication\n",
    "credential = DefaultAzureCredential()\n",
    "pg_token = credential.get_token(\"https://ossrdbms-aad.database.windows.net/.default\")\n",
    "\n",
    "# Your Azure AD username (from `az ad signed-in-user show`)\n",
    "aad_username = \"admin@MngEnvMCAP560696.onmicrosoft.com\"\n",
    "\n",
    "# Connect to database using AAD token authentication\n",
    "conn = psycopg2.connect(\n",
    "    host=host,\n",
    "    port=port,\n",
    "    database=database_name,\n",
    "    user=aad_username,\n",
    "    password=pg_token.token,\n",
    "    sslmode=\"require\",\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create contracts table\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS contracts (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        filename VARCHAR(255) NOT NULL,\n",
    "        title TEXT,\n",
    "        duration VARCHAR(100),\n",
    "        jurisdictions JSONB,\n",
    "        dates JSONB,\n",
    "        markdown TEXT,\n",
    "        raw_fields JSONB,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Create parties table with foreign key to contracts\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS parties (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        contract_id INTEGER REFERENCES contracts(id) ON DELETE CASCADE,\n",
    "        name TEXT,\n",
    "        address TEXT,\n",
    "        reference_name TEXT,\n",
    "        clause TEXT,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Create clauses table with foreign key to contracts\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS clauses (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        contract_id INTEGER REFERENCES contracts(id) ON DELETE CASCADE,\n",
    "        clause_type VARCHAR(100),\n",
    "        title TEXT,\n",
    "        text TEXT,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Create indexes for better query performance\n",
    "cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_parties_contract_id ON parties(contract_id)\")\n",
    "cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_parties_name ON parties(name)\")\n",
    "cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_clauses_contract_id ON clauses(contract_id)\")\n",
    "cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_clauses_type ON clauses(clause_type)\")\n",
    "cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_contracts_filename ON contracts(filename)\")\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"‚úì Tables created successfully:\")\n",
    "print(\"  - contracts (main table)\")\n",
    "print(\"  - parties (with FK to contracts)\")\n",
    "print(\"  - clauses (with FK to contracts)\")\n",
    "print(\"‚úì Indexes created for efficient querying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4d8bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconnect to database (previous connection was closed)\n",
    "pg_token = credential.get_token(\"https://ossrdbms-aad.database.windows.net/.default\")\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=host,\n",
    "    port=port,\n",
    "    database=database_name,\n",
    "    user=aad_username,\n",
    "    password=pg_token.token,\n",
    "    sslmode=\"require\",\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Insert all contract data\n",
    "for contract in all_contract_data:\n",
    "    # Insert into contracts table\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO contracts (filename, title, duration, jurisdictions, dates, markdown, raw_fields)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "        RETURNING id\n",
    "    \"\"\", (\n",
    "        contract.get('filename'),\n",
    "        contract.get('title'),\n",
    "        contract.get('duration'),\n",
    "        json.dumps(contract.get('jurisdictions', [])),\n",
    "        json.dumps(contract.get('dates', {})),\n",
    "        contract.get('markdown'),\n",
    "        json.dumps(contract.get('raw_fields', {}))\n",
    "    ))\n",
    "\n",
    "    contract_id = cursor.fetchone()[0]\n",
    "\n",
    "    # Insert parties\n",
    "    for party in contract.get('parties', []):\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO parties (contract_id, name, address, reference_name, clause)\n",
    "            VALUES (%s, %s, %s, %s, %s)\n",
    "        \"\"\", (\n",
    "            contract_id,\n",
    "            party.get('name'),\n",
    "            party.get('address'),\n",
    "            party.get('reference_name'),\n",
    "            party.get('clause')\n",
    "        ))\n",
    "\n",
    "    # Insert clauses\n",
    "    for clause in contract.get('clauses', []):\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO clauses (contract_id, clause_type, title, text)\n",
    "            VALUES (%s, %s, %s, %s)\n",
    "        \"\"\", (\n",
    "            contract_id,\n",
    "            clause.get('type'),\n",
    "            clause.get('title'),\n",
    "            clause.get('text')\n",
    "        ))\n",
    "\n",
    "    print(f\"‚úì Uploaded: {contract.get('filename')}\")\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"\\n‚úì Successfully uploaded {len(all_contract_data)} contracts to database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba38397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconnect to database and query the stored data\n",
    "pg_token = credential.get_token(\"https://ossrdbms-aad.database.windows.net/.default\")\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=host,\n",
    "    port=port,\n",
    "    database=database_name,\n",
    "    user=aad_username,\n",
    "    password=pg_token.token,\n",
    "    sslmode=\"require\",\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Query contracts\n",
    "print(\"üìÑ CONTRACTS TABLE:\")\n",
    "cursor.execute(\"SELECT id, filename, title, duration, jurisdictions, dates FROM contracts\")\n",
    "contracts_rows = cursor.fetchall()\n",
    "contracts_df = pd.DataFrame(contracts_rows, columns=['id', 'filename', 'title', 'duration', 'jurisdictions', 'dates'])\n",
    "print(contracts_df.to_string())\n",
    "\n",
    "# Query parties\n",
    "print(\"\\n\\nüë• PARTIES TABLE:\")\n",
    "cursor.execute(\"SELECT id, contract_id, name, address, reference_name FROM parties\")\n",
    "parties_rows = cursor.fetchall()\n",
    "parties_df = pd.DataFrame(parties_rows, columns=['id', 'contract_id', 'name', 'address', 'reference_name'])\n",
    "print(parties_df.to_string())\n",
    "\n",
    "# Query clauses\n",
    "print(\"\\n\\nüìù CLAUSES TABLE:\")\n",
    "cursor.execute(\"SELECT id, contract_id, clause_type, title, LEFT(text, 100) as text_preview FROM clauses\")\n",
    "clauses_rows = cursor.fetchall()\n",
    "clauses_df = pd.DataFrame(clauses_rows, columns=['id', 'contract_id', 'clause_type', 'title', 'text_preview'])\n",
    "print(clauses_df.to_string())\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"\\n‚úì Retrieved {len(contracts_rows)} contracts, {len(parties_rows)} parties, {len(clauses_rows)} clauses\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
